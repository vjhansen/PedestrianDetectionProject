{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Begreper\n",
    " - **Gradient descent (GD)**: algoritme for å minimere feil over flere steg.\n",
    " - **autodiff**: numerisk evaluering av den deriverte til en funksjon spesifisert av et dataprogram. Dette er ikke det samme som numerisk differensiering. Brukes for å finne gradientene i *gradient descent*.\n",
    " - **softmax**: brukes i nevrale nettverk for klassifisering, velger den mest sannsynlige klassifiseringen gitt flere input-verdier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kunstige nevrale nettverk (ANN)\n",
    "https://towardsdatascience.com/how-do-we-train-neural-networks-edd985562b73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspirasjonen kommer fra hjernens anatomi. Milliarder av nevroner i hjernebarken vår er tilkoblet via aksoner. Et nevron sender signaler til de nevronene det er tilkoblet.\n",
    "\n",
    "**Vekt**: sum(w*x)= w dot x\n",
    "http://neuralnetworksanddeeplearning.com/chap1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Linear Threshold Unit (LTU)**: 1957. Legger til vekt på inputs, aktiveringen av output gis i form av en steg-funksjon (0/1).\n",
    "- **Perceptron**: Flere lag av LTU. Et perceptron kan lære ved å forsterke vekten som fører til ønsket output.\n",
    "- **Multi-Layer perceptrons**: Legger til \"skjulte lag\" av LTU mellom input og output. Dette er et *deep neural network*.\n",
    "- **Moderne dype nevrale nettverk**: Erstatter steg-aktiveringen med en annen funksjon, f.eks. 'Tanh', 'reLU', 'Sigmoid'. Legger til softmax på output for å konvertere verdien på output til sannsynligheten for klassifisering. Treningen bruker gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "Gradient descent ved bruk av reverse-mode autodiff.\n",
    "\n",
    "For hvert steg i treningen:\n",
    "- Beregn output-feil\n",
    "- Beregn hvor mye hvert nevron i det forrige skjulte laget bidro.\n",
    "- Back-propagate den feilen i retning mot inputs.\n",
    "- Juster vekter for å redusere feil vha. gradient descent.\n",
    "- Repeter til systemet/output konvergerer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktiveringsfunksjoner (rectifier)\n",
    "https://en.wikipedia.org/wiki/Activation_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steg-funksjoner virker ikke sammen med gradient descent siden det ikke finnes noen gradient. \n",
    "\n",
    "Alternativene er:\n",
    "- Hyperbolsk tangens-funksjons (Tanh)\n",
    "- Logistisk (sigmoid/soft step)\n",
    "- Eksponentiell lineær-enhet (ELU): rask læring.\n",
    "- Rectified lineær-enhet (ReLU): vanlig, raske beregninger.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimaliseringsfunksjoner\n",
    "Alternativer som gir raskere læring i forhold til gradient descent. \n",
    "https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d\n",
    "- **Momentum-optimalisering**: Senker hastigheten når training-loss på output flater ut, og tar \n",
    "- **Nesterov Accelerated Gradient**: En variant av momentum, beregner momentum basert på gradienten fremfor deg.\n",
    "- **RMSProp**: \n",
    "- **Adam**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "Utviklet av Google.\n",
    "playground.tensorflow.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
